[prompts]
answer_template = """Answer the question based only on the following context:
{context}

Question: {question}
"""

[model_params]
# Controls hyperparameters of the main llm model used for Q&A with RAG
temperature = 0
model_name = "gpt-3.5-turbo"